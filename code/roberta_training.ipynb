{"cells":[{"cell_type":"markdown","metadata":{"id":"mobxbz2Hk3aO"},"source":["# installations and imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_5M-P5cjwqM"},"outputs":[],"source":["# install packages\n","!pip install -qq transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5871,"status":"ok","timestamp":1709760623822,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"hUt-nJ-Bj6nd","outputId":"ece31dc3-1cb0-43a1-ffdd-24b5e910c3e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"text/plain":["<torch._C.Generator at 0x78c605805ab0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# import libraries\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","import torch\n","from torch import nn, optim, cuda\n","from transformers import RobertaForSequenceClassification, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import Dataset, DataLoader\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","\n","# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# set up device for GPU usage\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709760623822,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"fjGDNL6CkqK5","outputId":"0f1eefcf-d78c-4ef5-da58-78bbe103ba23"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2400, 2)\n","(300, 2)\n","(1000, 2)\n","                                            sentence  label\n","0        It's crazy how fast this year is flying by.      0\n","1  I started reading a new book last night, and I...      0\n","2  Sarah's birthday is this weekend, and I heard ...      1\n","3  I'm really looking forward to summer break, I ...      0\n","4  Did you end up going on that hiking trip you w...      0\n","                                            sentence  label\n","0  I'm thinking about taking up yoga to help with...      0\n","1  My family and I are planning a trip to Europe ...      0\n","2                            It got amazing reviews.      0\n","3  The way they're avoiding direct answers about ...      1\n","4  Did you hear about that new restaurant that op...      0\n"]}],"source":["# import data\n","df_train = pd.read_csv('/content/drive/MyDrive/final_sets/slang-random_train.tsv', delimiter='\\t', encoding='utf-8',usecols=['sentence', 'label'])\n","df_dev = pd.read_csv('/content/drive/MyDrive/final_sets/slang-random_dev.tsv', delimiter='\\t', encoding='utf-8',usecols=['sentence', 'label'])\n","df_test = pd.read_csv('/content/drive/MyDrive/final_sets/full_test.tsv', delimiter='\\t', encoding='utf-8',usecols=['sentence', 'label'])\n","\n","\n","# shuffle df\n","df_train = df_train.sample(frac=1, random_state=42).reset_index(drop=True)\n","df_dev = df_dev.sample(frac=1, random_state=42).reset_index(drop=True)\n","df_test = df_test.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","print(df_train.shape)\n","print(df_dev.shape)\n","print(df_test.shape)\n","\n","print(df_train.head())\n","print(df_dev.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709760623823,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"HdPhnN9NlUef","outputId":"b58e08e1-8baf-4e09-8715-f29a937f3887"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2400 entries, 0 to 2399\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   sentence  2400 non-null   object\n"," 1   label     2400 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 37.6+ KB\n","None\n","~~~~~~~~~~~~~~~~~~~\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 300 entries, 0 to 299\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   sentence  300 non-null    object\n"," 1   label     300 non-null    int64 \n","dtypes: int64(1), object(1)\n","memory usage: 4.8+ KB\n","None\n","~~~~~~~~~~~~~~~~~~~\n","0    1200\n","1    1200\n","Name: label, dtype: int64\n","~~~~~~~~~~~~~~~~~~~\n","0    150\n","1    150\n","Name: label, dtype: int64\n"]}],"source":["print(df_train.info())\n","print('~~~~~~~~~~~~~~~~~~~')\n","print(df_dev.info())\n","print('~~~~~~~~~~~~~~~~~~~')\n","print(df_train.label.value_counts())\n","print('~~~~~~~~~~~~~~~~~~~')\n","print(df_dev.label.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1790,"status":"ok","timestamp":1709760625610,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"IbweHvf3bGg7","outputId":"d2277caf-fae9-413f-b770-e351f0fa28df"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# choose model\n","model_name = \"roberta-base\"\n","model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","\n","max_len = 512"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yin6vQBJsTM_"},"outputs":[],"source":["class SlangDataset(Dataset):\n","    \"\"\"\n","    Create a PyTorch dataset for the Slang data.\n","    \"\"\"\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        text = str(self.data.iloc[index]['sentence'])\n","        label = int(self.data.iloc[index]['label'])\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            truncation=True,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        return {\n","            'text': text,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jcXFzT-tH-h8"},"outputs":[],"source":["def create_data_loader(df, tokenizer, max_len, batch_size):\n","  \"\"\"\n","  Create a PyTorch DataLoader for the Slang data.\n","  \"\"\"\n","  ds = SlangDataset(\n","    dataframe=df,\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","  )\n","\n","  return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=4\n","  )\n","\n","\n","batch_size = 16\n","\n","train_data_loader = create_data_loader(df_train, tokenizer, max_len, batch_size)\n","dev_data_loader = create_data_loader(df_dev, tokenizer, max_len, batch_size)\n","test_data_loader = create_data_loader(df_test, tokenizer, max_len, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":683,"status":"ok","timestamp":1709760626292,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"eh3-O8POS6as","outputId":"3b6c01f0-4f66-4e43-cc87-928ef14a56dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 512])\n","torch.Size([16, 512])\n","{'text': [\"It's crazy how fast this year is flying by.\", \"I started reading a new book last night, and I can't put it down.\", \"Sarah's birthday is this weekend, and I heard her parents are letting her have a turnt sleepover.\", \"I'm really looking forward to summer break, I need some time off from all the stress of school.\", 'Did you end up going on that hiking trip you were planning?', \"The way Ethan keeps avoiding my texts is making me think he's up to something sus.\", 'It was amazing!', 'Have you heard about that new volunteer opportunity at the animal shelter?', 'Have you started thinking about where you want to go to college yet?', 'My friend keeps texting his crush paragraphs about how amazing she is...he needs to chill out with the simping.', \"I'm thinking of trying out for the school play this year; acting has always been a passion of mine.\", \"I don't know why, but the new girl in our class seems super sus to me.\", \"She's the biggest simp in our group.\", \"My parents are dragging me to a family gathering this Saturday, and I'm not looking forward to it at all.\", \"The cafeteria food is getting worse every day, I swear they don't even try anymore.\", 'That new restaurant downtown has amazing food, we have to go check it out soon.'], 'input_ids': tensor([[    0,   243,    18,  ...,     1,     1,     1],\n","        [    0,   100,   554,  ...,     1,     1,     1],\n","        [    0, 33671,    18,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  2387,  1041,  ...,     1,     1,     1],\n","        [    0,   133, 28538,  ...,     1,     1,     1],\n","        [    0,  1711,    92,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0])}\n"]}],"source":["data = next(iter(train_data_loader))\n","\n","print(data['input_ids'].shape)\n","print(data['attention_mask'].shape)\n","print(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4-F_PjuToGF"},"outputs":[],"source":["model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EXAJzL07UVbj"},"outputs":[],"source":["EPOCHS = 4\n","L2_lambda = 0.5\n","learning_rate = 0.00005\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=L2_lambda)\n","total_steps = len(train_data_loader) * EPOCHS\n","\n","scheduler = get_linear_schedule_with_warmup(\n","  optimizer,\n","  num_warmup_steps=0,\n","  num_training_steps=total_steps\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBNf2h96uXsW"},"outputs":[],"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","\n","def train_epoch(model, data_loader, optimizer, device, scheduler, n_examples):\n","    \"\"\"\n","    Train the model for one epoch.\n","    \"\"\"\n","\n","    model = model.train()\n","    losses = []\n","    correct_predictions = 0\n","\n","    for batch in data_loader:\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        targets = batch[\"label\"].to(device)\n","\n","        output = model(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            labels=targets\n","        )\n","\n","        logits = output.logits\n","        loss = output.loss\n","\n","        # Apply softmax to logits\n","        softmax_probs = nn.functional.softmax(logits, dim=1)\n","\n","        # Get predicted class using argmax\n","        preds = torch.argmax(softmax_probs, dim=1).cpu().numpy()\n","        label_ids = targets.to('cpu').numpy()\n","\n","        correct_predictions += np.sum(preds == label_ids)\n","\n","        losses.append(loss.item())\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","\n","    return correct_predictions / n_examples, np.mean(losses)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2l5cbW96uoIZ"},"outputs":[],"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","\n","def eval_model(model, data_loader, device, n_examples):\n","    \"\"\"\n","    Evaluate the model on the validation set.\n","    \"\"\"\n","\n","    model = model.eval()\n","    losses = []\n","    correct_predictions = 0\n","\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            targets = batch[\"label\"].to(device)\n","\n","            output = model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                labels=targets\n","            )\n","\n","            logits = output.logits\n","            loss = output.loss\n","\n","            # apply softmax to logits\n","            softmax_probs = nn.functional.softmax(logits, dim=1)\n","\n","            # get predicted class using argmax\n","            preds = torch.argmax(softmax_probs, dim=1).cpu().numpy()\n","            label_ids = targets.to('cpu').numpy()\n","\n","            correct_predictions += np.sum(preds == label_ids)\n","            losses.append(loss.item())\n","\n","    return correct_predictions / n_examples, np.mean(losses)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dum4_fp9WL1I"},"outputs":[],"source":["def get_predictions(model, data_loader, device):\n","  \"\"\"\n","  Get predictions from the model.\n","  \"\"\"\n","  model = model.eval()\n","  all_predictions = []\n","  all_targets = []\n","  all_logits = []\n","\n","  with torch.no_grad():\n","    for batch in data_loader:\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        targets = batch[\"label\"].to(device)\n","\n","        output = model(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            labels=targets\n","        )\n","\n","        logits = output.logits\n","        predictions = torch.argmax(logits, dim=1)\n","\n","        all_predictions.extend(predictions.cpu().numpy())\n","        all_targets.extend(targets.cpu().numpy())\n","        all_logits.extend(logits.cpu().numpy())\n","\n","  return all_predictions, all_targets, all_logits"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293959,"status":"ok","timestamp":1709760920960,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"dMXQ-8_6WQdL","outputId":"1757e712-2160-4eab-ae0d-b65c384415fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/4\n","----------\n","Train loss 0.11493491897776645 Accuracy 0.95\n","Dev   loss 0.0065007575771903105 Accuracy 0.9966666666666667\n","Dev Precision Score: 1.0\n","Dev Recall Score: 0.9933333333333333\n","Dev F1 Score: 0.9966555183946488\n","\n","[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n","[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n","Dev Logits:\n"," [array([ 5.118013, -5.058001], dtype=float32), array([ 5.1275325, -5.0843205], dtype=float32), array([ 5.127523 , -5.0926266], dtype=float32), array([-5.252527 ,  4.9567113], dtype=float32), array([ 5.0904064, -5.0529246], dtype=float32), array([ 5.1067104, -5.0565815], dtype=float32), array([ 5.0878716, -5.0245934], dtype=float32), array([-5.17196  ,  4.8967667], dtype=float32), array([-5.2107563,  4.880073 ], dtype=float32), array([ 5.098562 , -5.0348377], dtype=float32)]\n","Epoch 2/4\n","----------\n","Train loss 0.013076715621209586 Accuracy 0.9970833333333333\n","Dev   loss 2.080716196934717e-05 Accuracy 1.0\n","Dev Precision Score: 1.0\n","Dev Recall Score: 1.0\n","Dev F1 Score: 1.0\n","\n","[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n","[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n","Dev Logits:\n"," [array([ 5.4538097, -5.409337 ], dtype=float32), array([ 5.4629507, -5.4247417], dtype=float32), array([ 5.454275, -5.419324], dtype=float32), array([-5.479294 ,  5.2918396], dtype=float32), array([ 5.4559937, -5.426808 ], dtype=float32), array([ 5.4584074, -5.431321 ], dtype=float32), array([ 5.4272604, -5.379138 ], dtype=float32), array([-5.38146 ,  5.206621], dtype=float32), array([-5.418343 ,  5.2516546], dtype=float32), array([ 5.4350557, -5.3864326], dtype=float32)]\n","Epoch 3/4\n","----------\n","Train loss 3.681391803790272e-05 Accuracy 1.0\n","Dev   loss 1.4167374166917349e-05 Accuracy 1.0\n","Dev Precision Score: 1.0\n","Dev Recall Score: 1.0\n","Dev F1 Score: 1.0\n","\n","[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n","[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n","Dev Logits:\n"," [array([ 5.6298146, -5.5936537], dtype=float32), array([ 5.638952, -5.608951], dtype=float32), array([ 5.633055, -5.606373], dtype=float32), array([-5.662926,  5.495749], dtype=float32), array([ 5.635033 , -5.6115103], dtype=float32), array([ 5.6374607, -5.617139 ], dtype=float32), array([ 5.6008344, -5.56135  ], dtype=float32), array([-5.598646,  5.447972], dtype=float32), array([-5.6148043,  5.464483 ], dtype=float32), array([ 5.608795 , -5.5696774], dtype=float32)]\n","Epoch 4/4\n","----------\n","Train loss 2.9390450484546213e-05 Accuracy 1.0\n","Dev   loss 1.2724987037041788e-05 Accuracy 1.0\n","Dev Precision Score: 1.0\n","Dev Recall Score: 1.0\n","Dev F1 Score: 1.0\n","\n","[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n","[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n","Dev Logits:\n"," [array([ 5.680925, -5.647915], dtype=float32), array([ 5.6898904, -5.662968 ], dtype=float32), array([ 5.6843977, -5.6605816], dtype=float32), array([-5.712858 ,  5.5515423], dtype=float32), array([ 5.686609, -5.665569], dtype=float32), array([ 5.6892457, -5.671543 ], dtype=float32), array([ 5.651878, -5.61545 ], dtype=float32), array([-5.6520233,  5.5086   ], dtype=float32), array([-5.6671076,  5.52228  ], dtype=float32), array([ 5.6592827, -5.6235013], dtype=float32)]\n"]}],"source":["from collections import defaultdict\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","history = defaultdict(list)\n","\n","best_acc = 0\n","\n","for epoch in range(EPOCHS):\n","    print(f'Epoch {epoch + 1}/{EPOCHS}')\n","    print('-' * 10)\n","\n","    train_acc, train_loss = train_epoch(model, train_data_loader, optimizer, device, scheduler, len(df_train))\n","\n","    print(f'Train loss {train_loss} Accuracy {train_acc}')\n","\n","    dev_acc, dev_loss = eval_model(model, dev_data_loader, device, len(df_dev))\n","\n","    print(f'Dev   loss {dev_loss} Accuracy {dev_acc}')\n","\n","    dev_predictions, dev_targets, dev_logits = get_predictions(model, dev_data_loader, device)\n","    dev_precision = precision_score(dev_targets, dev_predictions, zero_division=0)\n","    dev_recall = recall_score(dev_targets, dev_predictions)\n","    dev_f1 = f1_score(dev_targets, dev_predictions)\n","\n","    print(f'Dev Precision Score: {dev_precision}')\n","    print(f'Dev Recall Score: {dev_recall}')\n","    print(f'Dev F1 Score: {dev_f1}')\n","\n","    print()\n","\n","    history['train_acc'].append(train_acc)\n","    history['train_loss'].append(train_loss)\n","    history['dev_acc'].append(dev_acc)\n","    history['dev_loss'].append(dev_loss)\n","    history['dev_precision'].append(dev_precision)\n","    history['dev_recall'].append(dev_recall)\n","    history['dev_f1'].append(dev_f1)\n","\n","    if dev_acc > best_acc:\n","        torch.save(model.state_dict(), 'best_model.bin')\n","        best_acc = dev_acc\n","\n","    print(dev_predictions)\n","    print(dev_targets)\n","    print(\"Dev Logits:\\n\", dev_logits[:10])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1709760920960,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"cSKuzSEGZIVz","outputId":"25cae4e8-2f6a-4407-92d8-08effebd882e"},"outputs":[{"name":"stdout","output_type":"stream","text":["AdamW (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    initial_lr: 5e-05\n","    lr: 0.0\n","    maximize: False\n","    weight_decay: 0.5\n",")\n","L2 Lambda: 0.5\n","Learning Rate: 5e-05\n"]}],"source":["print(optimizer)\n","print(\"L2 Lambda:\",L2_lambda)\n","print(\"Learning Rate:\", learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1709760920960,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"s7blIyGrhj8_","outputId":"301122e1-c2c6-4a6d-ecc2-c03cd40a0551"},"outputs":[{"name":"stdout","output_type":"stream","text":["defaultdict(<class 'list'>, {'train_acc': [0.95, 0.9970833333333333, 1.0, 1.0], 'train_loss': [0.11493491897776645, 0.013076715621209586, 3.681391803790272e-05, 2.9390450484546213e-05], 'dev_acc': [0.9966666666666667, 1.0, 1.0, 1.0], 'dev_loss': [0.0065007575771903105, 2.080716196934717e-05, 1.4167374166917349e-05, 1.2724987037041788e-05], 'dev_precision': [1.0, 1.0, 1.0, 1.0], 'dev_recall': [0.9933333333333333, 1.0, 1.0, 1.0], 'dev_f1': [0.9966555183946488, 1.0, 1.0, 1.0]})\n"]}],"source":["print(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":824,"status":"ok","timestamp":1709760921779,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"IEL9C4dZZuUq","outputId":"a8cc63fe-972c-470d-a9dc-f459edd1bd50"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["path1 = \"/content/best_model.bin\"\n","\n","model_name = \"roberta-base\"\n","model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","model = model.to(device)\n","\n","model.load_state_dict(torch.load(path1))\n","\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9430,"status":"ok","timestamp":1709760931206,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"VwRMMIvGZ5xi","outputId":"49d31516-891e-4e3a-c2c0-a3ca2d4605a5"},"outputs":[{"data":{"text/plain":["0.667"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["test_acc, _ = eval_model(model, test_data_loader, device, len(df_test))\n","test_acc.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4ARzX1oGd6A"},"outputs":[],"source":["test_predictions, test_targets, test_logits = get_predictions(model, test_data_loader, device)\n","test_precision = precision_score(test_targets, test_predictions, zero_division=0)\n","test_recall = recall_score(test_targets, test_predictions)\n","test_f1 = f1_score(test_targets, test_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1709760940495,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"iJZ65EXqGx6X","outputId":"bba34d85-edfd-4da2-9a42-93a7488af223"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Precision Score: 0.9513513513513514\n","Test Recall Score: 0.352\n","Test F1 Score: 0.5138686131386861\n"]}],"source":["print(f'Test Precision Score: {test_precision}')\n","print(f'Test Recall Score: {test_recall}')\n","print(f'Test F1 Score: {test_f1}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709760940495,"user":{"displayName":"Jessica Cusi","userId":"17791983850156202788"},"user_tz":300},"id":"5FNl9MvMG_4Y","outputId":"8e033dd4-4cdd-4576-d385-78268e34a2ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","[1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"]}],"source":["print(test_predictions)\n","print(test_targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rieLpjLylwgK"},"outputs":[],"source":["# append test results to test dataframe and export\n","df_test['prediction'] = test_predictions\n","\n","df_test['match'] = np.where(df_test['label'] == df_test['prediction'], True, False)\n","df_test\n","\n","df_test.to_csv('/content/drive/MyDrive/final_sets/results.tsv',sep='\\t',index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[{"file_id":"12cWtY7ePG3ThZrixaIL9iWIcS1D3rZrx","timestamp":1709058905115}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
